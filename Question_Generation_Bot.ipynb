{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install -U transformers==3.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laiv1bv4IvFF",
        "outputId": "72fdac4c-9070-4033-a27f-530eaf23acab"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==3.0.0\n",
            "  Downloading transformers-3.0.0-py3-none-any.whl (754 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m754.6/754.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from transformers==3.0.0) (1.25.2)\n",
            "Collecting tokenizers==0.8.0-rc4 (from transformers==3.0.0)\n",
            "  Downloading tokenizers-0.8.0rc4.tar.gz (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.0/97.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from transformers==3.0.0) (24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==3.0.0) (3.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==3.0.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==3.0.0) (4.66.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==3.0.0) (2024.5.15)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from transformers==3.0.0) (0.1.99)\n",
            "Collecting sacremoses (from transformers==3.0.0)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==3.0.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==3.0.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==3.0.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==3.0.0) (2024.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==3.0.0) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==3.0.0) (1.4.2)\n",
            "Building wheels for collected packages: tokenizers\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build tokenizers\n",
            "\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m nltk.downloader punkt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQZe65PDJ3Mm",
        "outputId": "45a2a5cb-6cff-46d6-cf23-c5d78935c483"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCRdnyUhU1w9sTJLqSzSMt3Twoos5D7hUk\""
      ],
      "metadata": {
        "id": "XQ6xjrpQAzuE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "# Initialize the model and tokenizer for FLAN-T5           ##valhalla/t5-base-qg-hl\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
        "\n",
        "# Function to generate questions for a given topic\n",
        "def generate_questions_for_topic(topic, num_questions=20):\n",
        "    input_text = f\"generate questions on the topic: {topic}\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "    outputs = model.generate(input_ids, max_length=100, num_return_sequences=num_questions, num_beams=num_questions)\n",
        "    questions = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
        "    return questions\n",
        "\n",
        "# Interactive prompt for user input\n",
        "user_topic = input(\"Please enter a topic: \")\n",
        "\n",
        "# Generate and print questions for the user-provided topic\n",
        "print(f\"\\nTopic: {user_topic}\")\n",
        "questions = generate_questions_for_topic(user_topic)\n",
        "for i, question in enumerate(questions, 1):\n",
        "    print(f\"Question {i}: {question}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_55AUJFk_l8r",
        "outputId": "ec31a593-8020-406f-b323-87cf09079870"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter a topic: Sports\n",
            "\n",
            "Topic: Sports\n",
            "Question 1: What is the name of the sport that sports are played in?\n",
            "Question 2: What is the name of the sport that sports are a part of?\n",
            "Question 3: What is the name of a sports team?\n",
            "Question 4: what is the name of a sports team?\n",
            "Question 5: What is the name of a sports league?\n",
            "Question 6: What is the name of the sport that is played in the United States?\n",
            "Question 7: What is a sport called?\n",
            "Question 8: What is the name of the sport that sports are played on?\n",
            "Question 9: What is the name of the sport that is played in a sports hall of fame?\n",
            "Question 10: What is the name of a sport that is played in a stadium?\n",
            "Question 11: What type of sport is football?\n",
            "Question 12: What is a sports team called?\n",
            "Question 13: What is the sport of football called?\n",
            "Question 14: What is the name of a sport?\n",
            "Question 15: What is the name of the sport that is played on a football field?\n",
            "Question 16: What is a sports team?\n",
            "Question 17: What is the name of the sport that is played in the US?\n",
            "Question 18: What is the name of a sport that is played on a field?\n",
            "Question 19: What is the name of a sport that is played on a regular basis?\n",
            "Question 20: What kind of sport is football?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JveLXSsELKlo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}